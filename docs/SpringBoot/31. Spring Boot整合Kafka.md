<font style="color:rgb(76, 73, 72);">Kafka是一个分布式的、可分区的、可复制的消息系统，下面是Kafka的几个基本术语：</font>

1. <font style="color:rgb(76, 73, 72);">Kafka将消息以</font>**<font style="color:rgb(76, 73, 72);">topic</font>**<font style="color:rgb(76, 73, 72);">为单位进行归纳；</font>
2. <font style="color:rgb(76, 73, 72);">将向Kafka topic发布消息的程序成为</font>**<font style="color:rgb(76, 73, 72);">producers</font>**<font style="color:rgb(76, 73, 72);">；</font>
3. <font style="color:rgb(76, 73, 72);">将预订topics并消费消息的程序成为</font>**<font style="color:rgb(76, 73, 72);">consumer</font>**<font style="color:rgb(76, 73, 72);">；</font>
4. <font style="color:rgb(76, 73, 72);">Kafka以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个</font>**<font style="color:rgb(76, 73, 72);">broker</font>**<font style="color:rgb(76, 73, 72);">。</font>

<font style="color:rgb(76, 73, 72);">producers通过网络将消息发送到Kafka集群，集群向消费者提供消息，如下图所示：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713082876-10904bf9-0136-4846-8a1a-8758988e47d0.png)

<font style="color:rgb(76, 73, 72);">创建一个topic时，可以指定</font>**<font style="color:rgb(76, 73, 72);">partitions</font>**<font style="color:rgb(76, 73, 72);">（分区）数目，partitions数越多，其吞吐量也越大，但是需要的资源也越多，同时也会导致更高的不可用性，kafka在接收到producers发送的消息之后，会根据均衡策略将消息存储到不同的partitions中：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713082843-8115b7df-8f1c-423a-bd5d-d0bea5a31363.png)

<font style="color:rgb(76, 73, 72);">在每个partitions中，消息以顺序存储，最晚接收的的消息会最后被消费。</font>

<font style="color:rgb(76, 73, 72);">producers在向kafka集群发送消息的时候，可以通过指定partitions来发送到指定的partitions中。也可以通过指定均衡策略来将消息发送到不同的partitions中。如果不指定，就会采用默认的随机均衡策略，将消息随机的存储到不同的partitions中。</font>

<font style="color:rgb(76, 73, 72);">在consumer消费消息时，kafka使用offset来记录当前消费的位置：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713083615-c24ff708-ba78-433c-baee-ac0e48277938.png)

<font style="color:rgb(76, 73, 72);">在kafka的设计中，可以有多个不同的group来同时消费同一个topic下的消息，如图，我们有两个不同的group同时消费，他们的的消费的记录位置offset各不项目，不互相干扰。</font>

<font style="color:rgb(76, 73, 72);">对于一个group而言，consumer的数量不应该多于partitions的数量，因为在一个group中，每个partitions至多只能绑定到一个consumer上，即一个consumer可以消费多个partitions，一个partitions只能给一个consumer消费。因此，若一个group中的consumer数量大于partitions数量的话，多余的consumer将不会收到任何消息。</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713083092-67ac1c95-40f3-4f7d-8bfd-09cd42def0e7.png)

<h2 id="Kafka安装使用"><font style="color:rgb(76, 73, 72);">Kafka安装使用</font></h2>
<font style="color:rgb(76, 73, 72);">这里演示在Windows下Kafka安装与使用。Kafka下载地址：</font>[<font style="color:rgb(76, 73, 72);">http://kafka.apache.org/downloads</font>](http://kafka.apache.org/downloads)<font style="color:rgb(76, 73, 72);">，选择二进制文件下载（Binary downloads），然后解压即可。</font>

<font style="color:rgb(76, 73, 72);">Kafka的配置文件位于config目录下，因为Kafka集成了Zookeeper（Kafka存储消息的地方），所以config目录下除了有Kafka的配置文件server.properties外，还可以看到一个Zookeeper配置文件zookeeper.properties：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713083792-cb8951d8-9012-48a8-adda-762b5c71c08e.png)

<font style="color:rgb(76, 73, 72);">打开server.properties，将</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">broker.id</font>_`<font style="color:rgb(76, 73, 72);">的值修改为1，每个broker的id都必须设置为Integer类型，且不能重复。Zookeeper的配置保持默认即可。</font>

<font style="color:rgb(76, 73, 72);">接下来开始使用Kafka。</font>

<h3 id="启动Zookeeper"><font style="color:rgb(76, 73, 72);">启动Zookeeper</font></h3>
<font style="color:rgb(76, 73, 72);">在Windows下执行下面这些命令可能会出现</font><font style="color:red;">找不到或无法加载主类</font><font style="color:rgb(76, 73, 72);">的问题，解决方案可参考：</font>[<font style="color:rgb(76, 73, 72);">https://blog.csdn.net/cx2932350/article/details/78870135</font>](https://blog.csdn.net/cx2932350/article/details/78870135)<font style="color:rgb(76, 73, 72);">。</font>

<font style="color:rgb(76, 73, 72);">在Kafka根目录下使用cmd执行下面这条命令，启动ZK：</font>

```bash
bin\windows\zookeeper-server-start.bat config\zookeeper.properties
```

<font style="color:rgb(76, 73, 72);">在Linux下，可以使用后台进程的方式启动ZK：</font>

```bash
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```

<h3 id="启动Kafka"><font style="color:rgb(76, 73, 72);">启动Kafka</font></h3>
<font style="color:rgb(76, 73, 72);">执行下面这条命令启动Kafka：</font>

```bash
bin\windows\kafka-server-start.bat config\server.properties
```

<font style="color:rgb(76, 73, 72);">Linux对应命令：</font>

```bash
bin/kafka-server-start.sh config/server.properties
```

<font style="color:rgb(76, 73, 72);">当看到命令行打印如下信息，说明启动完毕:</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713083460-97dfb424-639c-4ff4-a1f1-c0f45c6cf834.png)

<h3 id="创建Topic"><font style="color:rgb(76, 73, 72);">创建Topic</font></h3>
<font style="color:rgb(76, 73, 72);">执行下面这条命令创建一个Topic</font>

```bash
bin\windows\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```

<font style="color:rgb(76, 73, 72);">这条命令的意思是，创建一个Topic到ZK（指定ZK的地址），副本个数为1，分区数为1，Topic的名称为test。</font>

<font style="color:rgb(76, 73, 72);">Linux对应的命令为:</font>

```bash
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```

<font style="color:rgb(76, 73, 72);">创建好后我们可以查看Kafka里的Topic列表：</font>

```bash
bin\windows\kafka-topics.bat --list --zookeeper localhost:2181
```

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713084888-d39d834e-f666-463a-95bc-df503beb90ee.png)

<font style="color:rgb(76, 73, 72);">可看到目前只包含一个我们刚创建的test Topic。</font>

<font style="color:rgb(76, 73, 72);">Linux对应的命令为：</font>

```bash
bin/kafka-topics.sh --list --zookeeper localhost:2181
```

<font style="color:rgb(76, 73, 72);">查看test Topic的具体信息：</font>

```bash
bin\windows\kafka-topics.bat --describe --zookeeper localhost:2181 --topic test
```

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713085979-1347e893-1bca-4b33-9ebe-3065eed6a670.png)

<font style="color:rgb(76, 73, 72);">Linux对应的命令为：</font>

```bash
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test
```

<h3 id="生产消息和消费消息"><font style="color:rgb(76, 73, 72);">生产消息和消费消息</font></h3>
**<font style="color:rgb(76, 73, 72);">启动Producers</font>**

```bash
bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic test
```

<font style="color:rgb(76, 73, 72);">9092为生产者的默认端口号。这里启动了生产者，准备往test Topic里发送数据。</font>

<font style="color:rgb(76, 73, 72);">Linux下对应的命令为：</font>

```bash
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
```

**<font style="color:rgb(76, 73, 72);">启动Consumers</font>**

<font style="color:rgb(76, 73, 72);">接着启动一个消费者用于消费生产者生产的数据，新建一个cmd窗口，输入下面这条命令：</font>

```bash
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
```

`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">from-beginning</font>_`<font style="color:rgb(76, 73, 72);">表示从头开始读取数据。</font>

<font style="color:rgb(76, 73, 72);">Linux下对应的命令为：</font>

```bash
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```

<font style="color:rgb(76, 73, 72);">启动好生产者和消费者后我们在生产者里生产几条数据:</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713085924-0a7485f4-7242-497f-81c5-34529f5a3d60.png)

<font style="color:rgb(76, 73, 72);">消费者成功接收到数据：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713085939-99a86c1b-e806-48b6-b1cc-6184dd086a21.png)

<h2 id="Spring-Boot整合Kafaka"><font style="color:rgb(76, 73, 72);">Spring Boot整合Kafaka</font></h2>
<font style="color:rgb(76, 73, 72);">上面简单介绍了Kafka的使用，下面我们开始在Spring Boot里使用Kafka。</font>

<font style="color:rgb(76, 73, 72);">新建一个Spring Boot项目，版本为2.1.3.RELEASE，并引入如下依赖:</font>

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
  <groupId>org.springframework.kafka</groupId>
  <artifactId>spring-kafka</artifactId>
</dependency>
```

<h3 id="生产者配置"><font style="color:rgb(76, 73, 72);">生产者配置</font></h3>
<font style="color:rgb(76, 73, 72);">新建一个Java配置类</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaProducerConfig</font>_`<font style="color:rgb(76, 73, 72);">，用于配置生产者：</font>

```java
@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(
            ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,
            bootstrapServers);
        configProps.put(
            ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
            StringSerializer.class);
        configProps.put(
            ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
            StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

<font style="color:rgb(76, 73, 72);">首先我们配置了一个</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">producerFactory</font>_`<font style="color:rgb(76, 73, 72);">，方法里配置了Kafka Producer实例的策略。</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">bootstrapServers</font>_`<font style="color:rgb(76, 73, 72);">为Kafka生产者的地址，我们在配置文件application.yml里配置它：</font>

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
```

`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG</font>_`<font style="color:rgb(76, 73, 72);">和</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG</font>_`<font style="color:rgb(76, 73, 72);">指定了key，value序列化策略，这里指定为Kafka提供的</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">StringSerializer</font>_`<font style="color:rgb(76, 73, 72);">，因为我们暂时只发送简单的String类型的消息。</font>

<font style="color:rgb(76, 73, 72);">接着我们使用</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">producerFactory</font>_`<font style="color:rgb(76, 73, 72);">配置了</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">kafkaTemplate</font>_`<font style="color:rgb(76, 73, 72);">，其包含了发送消息的便捷方法，后面我们就用这个对象来发送消息。</font>

<h3 id="发布消息"><font style="color:rgb(76, 73, 72);">发布消息</font></h3>
<font style="color:rgb(76, 73, 72);">配置好生产者，我们就可以开始发布消息了。</font>

<font style="color:rgb(76, 73, 72);">新建一个</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">SendMessageController</font>_`<font style="color:rgb(76, 73, 72);">：</font>

```java
@RestController
public class SendMessageController {

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    @GetMapping("send/{message}")
    public void send(@PathVariable String message) {
        this.kafkaTemplate.send("test", message);
    }
}
```

<font style="color:rgb(76, 73, 72);">我们注入了</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">kafkaTemplate</font>_`<font style="color:rgb(76, 73, 72);">对象，key-value都为String类型，并通过它的</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">send</font>_`<font style="color:rgb(76, 73, 72);">方法来发送消息。其中</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">test</font>_`<font style="color:rgb(76, 73, 72);">为Topic的名称，上面我们已经使用命令创建过这个Topic了。</font>

`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">send</font>_`<font style="color:rgb(76, 73, 72);">方法是一个异步方法，我们可以通过回调的方式来确定消息是否发送成功，我们改造</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">SendMessageController</font>_`<font style="color:rgb(76, 73, 72);">：</font>

```java
@RestController
public class SendMessageController {

    private Logger logger = LoggerFactory.getLogger(this.getClass());

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    @GetMapping("send/{message}")
    public void send(@PathVariable String message) {
        ListenableFuture<SendResult<String, String>> future = this.kafkaTemplate.send("test", message);
        future.addCallback(new ListenableFutureCallback<SendResult<String, String>>() {
            @Override
            public void onSuccess(SendResult<String, String> result) {
                logger.info("成功发送消息：{}，offset=[{}]", message, result.getRecordMetadata().offset());
            }

            @Override
            public void onFailure(Throwable ex) {
                logger.error("消息：{} 发送失败，原因：{}", message, ex.getMessage());
            }
        });
    }
}
```

<font style="color:rgb(76, 73, 72);">消息发送成功后，会回调</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">onSuccess</font>_`<font style="color:rgb(76, 73, 72);">方法，发送失败后回调</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">onFailure</font>_`<font style="color:rgb(76, 73, 72);">方法。</font>

<h3 id="消费者配置"><font style="color:rgb(76, 73, 72);">消费者配置</font></h3>
<font style="color:rgb(76, 73, 72);">接着我们来配置消费者，新建一个Java配置类</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaConsumerConfig</font>_`<font style="color:rgb(76, 73, 72);">：</font>

```java
@EnableKafka
@Configuration
public class KafkaConsumerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.group-id}")
    private String consumerGroupId;

    @Value("${spring.kafka.consumer.auto-offset-reset}")
    private String autoOffsetReset;

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,
            bootstrapServers);
        props.put(
            ConsumerConfig.GROUP_ID_CONFIG,
            consumerGroupId);
        props.put(
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,
            autoOffsetReset);
        props.put(
            ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
            StringDeserializer.class);
        props.put(
            ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
            StringDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory
        = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```

`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">consumerGroupId</font>_`<font style="color:rgb(76, 73, 72);">和</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">autoOffsetReset</font>_`<font style="color:rgb(76, 73, 72);">需要在application.yml里配置：</font>

```yaml
spring:
  kafka:
    consumer:
      group-id: test-consumer
      auto-offset-reset: latest
```

<font style="color:rgb(76, 73, 72);">其中</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">group-id</font>_`<font style="color:rgb(76, 73, 72);">将消费者进行分组（你也可以不进行分组），组名为</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">test-consumer</font>_`<font style="color:rgb(76, 73, 72);">，并指定了消息读取策略，包含四个可选值：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713085968-b45b908f-20f8-40e8-ad65-7245ef81cc2e.png)

+ <font style="color:rgb(76, 73, 72);">earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费</font>
+ <font style="color:rgb(76, 73, 72);">latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据</font>
+ <font style="color:rgb(76, 73, 72);">none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常</font>
+ <font style="color:rgb(76, 73, 72);">exception:直接抛出异常</font>

<font style="color:rgb(76, 73, 72);">在</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaConsumerConfig</font>_`<font style="color:rgb(76, 73, 72);">中我们配置了</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">ConsumerFactory</font>_`<font style="color:rgb(76, 73, 72);">和</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaListenerContainerFactory</font>_`<font style="color:rgb(76, 73, 72);">。当这两个Bean成功注册到Spring IOC容器中后，我们便可以使用</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@KafkaListener</font>_`<font style="color:rgb(76, 73, 72);">注解来监听消息了。</font>

<font style="color:rgb(76, 73, 72);">配置类上需要</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@EnableKafka</font>_`<font style="color:rgb(76, 73, 72);">注释才能在Spring托管Bean上检测</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@KafkaListener</font>_`<font style="color:rgb(76, 73, 72);">注解。</font>

<h3 id="消息消费"><font style="color:rgb(76, 73, 72);">消息消费</font></h3>
<font style="color:rgb(76, 73, 72);">配置好消费者，我们就可以开始消费消息了，新建</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaMessageListener</font>_`<font style="color:rgb(76, 73, 72);">：</font>

```java
@Component
public class KafkaMessageListener {

    private Logger logger = LoggerFactory.getLogger(this.getClass());

    @KafkaListener(topics = "test", groupId = "test-consumer")
    public void listen(String message) {
        logger.info("接收消息: {}", message);
    }
}
```

<font style="color:rgb(76, 73, 72);">我们通过</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@KafkaListener</font>_`<font style="color:rgb(76, 73, 72);">注解来监听名称为test的Topic，消费者分组的组名为</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">test-consumer</font>_`<font style="color:rgb(76, 73, 72);">。</font>

<h3 id="演示"><font style="color:rgb(76, 73, 72);">演示</font></h3>
<font style="color:rgb(76, 73, 72);">启动Spring Boot项目，启动过程中，控制台会输出Kafka的配置，启动好后，访问</font>[<font style="color:rgb(76, 73, 72);">http://localhost:8080/send/hello,mrbird</font>](http://localhost:8080/send/hello,mrbird)<font style="color:rgb(76, 73, 72);">，控制台输出如下：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713085996-d9106046-6074-4029-a7ab-afde24a52213.png)

<h3 id="KafkaListener详解"><font style="color:rgb(76, 73, 72);">@KafkaListener详解</font></h3>
`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@KafkaListener</font>_`<font style="color:rgb(76, 73, 72);">除了可以指定Topic名称和分组id外，我们还可以同时监听来自多个Topic的消息:</font>

```java
@KafkaListener(topics = "topic1, topic2")
```

<font style="color:rgb(76, 73, 72);">我们还可以通过</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@Header</font>_`<font style="color:rgb(76, 73, 72);">注解来获取当前消息来自哪个分区（partitions）:</font>

```java
@KafkaListener(topics = "test", groupId = "test-consumer")
public void listen(@Payload String message,
                   @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition) {
    logger.info("接收消息: {}，partition：{}", message, partition);
}
```

<font style="color:rgb(76, 73, 72);">重启项目，再次访问</font>[<font style="color:rgb(76, 73, 72);">http://localhost:8080/send/hello,mrbird</font>](http://localhost:8080/send/hello,mrbird)<font style="color:rgb(76, 73, 72);">，控制台输出如下：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713086713-d572c424-0c1e-4d29-a5a8-005dd4de31df.png)

<font style="color:rgb(76, 73, 72);">因为我们没有进行分区，所以test Topic只有一个区，下标为0。</font>

<font style="color:rgb(76, 73, 72);">我们可以通过</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">@KafkaListener</font>_`<font style="color:rgb(76, 73, 72);">来指定只接收来自特定分区的消息：</font>

```java
@KafkaListener(groupId = "test-consumer",
               topicPartitions = @TopicPartition(topic = "test",
                                                 partitionOffsets = {
                                                     @PartitionOffset(partition = "0", initialOffset = "0")
                                                 }))
public void listen(@Payload String message,
                   @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition) {
    logger.info("接收消息: {}，partition：{}", message, partition);
}
```

<font style="color:rgb(76, 73, 72);">如果不需要指定</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">initialOffset</font>_`<font style="color:rgb(76, 73, 72);">，上面代码可以简化为：</font>

```java
@KafkaListener(groupId = "test-consumer", 
               topicPartitions = @TopicPartition(topic = "test", partitions = { "0", "1" }))
```

<h3 id="消息过滤器"><font style="color:rgb(76, 73, 72);">消息过滤器</font></h3>
<font style="color:rgb(76, 73, 72);">我们可以为消息监听添加过滤器来过滤一些特定的信息。我们在消费者配置类</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaConsumerConfig</font>_`<font style="color:rgb(76, 73, 72);">的</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">kafkaListenerContainerFactory</font>_`<font style="color:rgb(76, 73, 72);">方法里配置过滤规则：</font>

```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory<String, String> factory
    = new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    // ------- 过滤配置 --------
    factory.setRecordFilterStrategy(
        r -> r.value().contains("fuck")
    );
    return factory;
}
```

`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">setRecordFilterStrategy</font>_`<font style="color:rgb(76, 73, 72);">接收</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">RecordFilterStrategy<K, V></font>_`<font style="color:rgb(76, 73, 72);">，他是一个函数式接口：</font>

```java
public interface RecordFilterStrategy<K, V> {
    boolean filter(ConsumerRecord<K, V> var1);
}
```

<font style="color:rgb(76, 73, 72);">所以我们用lambda表达式指定了上面这条规则，即如果消息内容包含</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">fuck</font>_`<font style="color:rgb(76, 73, 72);">这个粗鄙之语的时候，则不接受消息。</font>

<font style="color:rgb(76, 73, 72);">配置好后我们重启项目，分别发送下面这两条请求：</font>

1. [<font style="color:rgb(76, 73, 72);">http://localhost:8080/send/fuck,mrbird</font>](http://localhost:8080/send/fuck,mrbird)
2. [<font style="color:rgb(76, 73, 72);">http://localhost:8080/send/love,mrbird</font>](http://localhost:8080/send/love,mrbird)

<font style="color:rgb(76, 73, 72);">观察控制台：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713086866-0db300a3-636b-4b94-903c-681f53d87ec4.png)

<font style="color:rgb(76, 73, 72);">可以看到，fuck,mrbird这条消息没有被接收。</font>

<h3 id="发送复杂的消息"><font style="color:rgb(76, 73, 72);">发送复杂的消息</font></h3>
<font style="color:rgb(76, 73, 72);">截至目前位置我们只发送了简单的字符串类型的消息，我们可以自定义消息转换器来发送复杂的消息。</font>

**<font style="color:rgb(76, 73, 72);">定义消息实体</font>**

<font style="color:rgb(76, 73, 72);">创建一个Message类：</font>

```java
public class Message implements Serializable {
    private static final long serialVersionUID = 6678420965611108427L;

    private String from;

    private String message;

    public Message() {

    }

    public Message(String from, String message) {
        this.from = from;
        this.message = message;
    }

    @Override
    public String toString() {
        return "Message{" +
        "from='" + from + '\'' +
        ", message='" + message + '\'' +
        '}';
    }

    // get set 略
}
```

**<font style="color:rgb(76, 73, 72);">改造消息生产者配置</font>**

```java
@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public ProducerFactory<String, Message> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(
            ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,
            bootstrapServers);
        configProps.put(
            ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
            StringSerializer.class);
        configProps.put(
            ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
            JsonSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, Message> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

<font style="color:rgb(76, 73, 72);">我们将value序列化策略指定为了Kafka提供的</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">JsonSerializer</font>_`<font style="color:rgb(76, 73, 72);">，并且kafkaTemplate返回类型为</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaTemplate<String, Message></font>_`<font style="color:rgb(76, 73, 72);">。</font>

**<font style="color:rgb(76, 73, 72);">发送新的消息</font>**

<font style="color:rgb(76, 73, 72);">在</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">SendMessageController</font>_`<font style="color:rgb(76, 73, 72);">里发送复杂的消息:</font>

```java
@Autowired
private KafkaTemplate<String, Message> kafkaTemplate;

@GetMapping("send/{message}")
public void sendMessage(@PathVariable String message) {
    this.kafkaTemplate.send("test", new Message("mrbird", message));
}
```

**<font style="color:rgb(76, 73, 72);">修改消费者配置</font>**

<font style="color:rgb(76, 73, 72);">修改消费者配置</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaConsumerConfig</font>_`<font style="color:rgb(76, 73, 72);">：</font>

```java
@EnableKafka
@Configuration
public class KafkaConsumerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.group-id}")
    private String consumerGroupId;

    @Value("${spring.kafka.consumer.auto-offset-reset}")
    private String autoOffsetReset;

    @Bean
    public ConsumerFactory<String, Message> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(
            ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,
            bootstrapServers);
        props.put(
            ConsumerConfig.GROUP_ID_CONFIG,
            consumerGroupId);
        props.put(
            ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,
            autoOffsetReset);
        return new DefaultKafkaConsumerFactory<>(
            props,
            new StringDeserializer(),
            new JsonDeserializer<>(Message.class));
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Message> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Message> factory
        = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```

**<font style="color:rgb(76, 73, 72);">修改消息监听</font>**

<font style="color:rgb(76, 73, 72);">修改</font>`_<font style="color:rgb(65, 74, 81);background-color:rgb(251, 251, 251);">KafkaMessageListener</font>_`<font style="color:rgb(76, 73, 72);">：</font>

```java
@KafkaListener(topics = "test", groupId = "test-consumer")
public void listen(Message message) {
logger.info("接收消息: {}", message);
}
```

<font style="color:rgb(76, 73, 72);">重启项目，访问</font>[<font style="color:rgb(76, 73, 72);">http://localhost:8080/send/hello</font>](http://localhost:8080/send/hello)<font style="color:rgb(76, 73, 72);">，控制台输出如下：</font>

![](https://cdn.nlark.com/yuque/0/2024/png/48200602/1734713086856-d3ad3dbb-b969-43e2-8fe8-389818a40f6c.png)

<h3 id="更多配置"><font style="color:rgb(76, 73, 72);">更多配置</font></h3>
```properties
spring.kafka.admin.client-id= # ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.admin.fail-fast=false # Whether to fail fast if the broker is not available on startup.
spring.kafka.admin.properties.*= # Additional admin-specific properties used to configure the client.
spring.kafka.admin.ssl.key-password= # Password of the private key in the key store file.
spring.kafka.admin.ssl.key-store-location= # Location of the key store file.
spring.kafka.admin.ssl.key-store-password= # Store password for the key store file.
spring.kafka.admin.ssl.key-store-type= # Type of the key store.
spring.kafka.admin.ssl.protocol= # SSL protocol to use.
spring.kafka.admin.ssl.trust-store-location= # Location of the trust store file.
spring.kafka.admin.ssl.trust-store-password= # Store password for the trust store file.
spring.kafka.admin.ssl.trust-store-type= # Type of the trust store.
spring.kafka.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Applies to all components unless overridden.
spring.kafka.client-id= # ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.consumer.auto-commit-interval= # Frequency with which the consumer offsets are auto-committed to Kafka if 'enable.auto.commit' is set to true.
spring.kafka.consumer.auto-offset-reset= # What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.
spring.kafka.consumer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for consumers.
spring.kafka.consumer.client-id= # ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.consumer.enable-auto-commit= # Whether the consumer's offset is periodically committed in the background.
spring.kafka.consumer.fetch-max-wait= # Maximum amount of time the server blocks before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by "fetch-min-size".
spring.kafka.consumer.fetch-min-size= # Minimum amount of data the server should return for a fetch request.
spring.kafka.consumer.group-id= # Unique string that identifies the consumer group to which this consumer belongs.
spring.kafka.consumer.heartbeat-interval= # Expected time between heartbeats to the consumer coordinator.
spring.kafka.consumer.key-deserializer= # Deserializer class for keys.
spring.kafka.consumer.max-poll-records= # Maximum number of records returned in a single call to poll().
spring.kafka.consumer.properties.*= # Additional consumer-specific properties used to configure the client.
spring.kafka.consumer.ssl.key-password= # Password of the private key in the key store file.
spring.kafka.consumer.ssl.key-store-location= # Location of the key store file.
spring.kafka.consumer.ssl.key-store-password= # Store password for the key store file.
spring.kafka.consumer.ssl.key-store-type= # Type of the key store.
spring.kafka.consumer.ssl.protocol= # SSL protocol to use.
spring.kafka.consumer.ssl.trust-store-location= # Location of the trust store file.
spring.kafka.consumer.ssl.trust-store-password= # Store password for the trust store file.
spring.kafka.consumer.ssl.trust-store-type= # Type of the trust store.
spring.kafka.consumer.value-deserializer= # Deserializer class for values.
spring.kafka.jaas.control-flag=required # Control flag for login configuration.
spring.kafka.jaas.enabled=false # Whether to enable JAAS configuration.
spring.kafka.jaas.login-module=com.sun.security.auth.module.Krb5LoginModule # Login module.
spring.kafka.jaas.options= # Additional JAAS options.
spring.kafka.listener.ack-count= # Number of records between offset commits when ackMode is "COUNT" or "COUNT_TIME".
spring.kafka.listener.ack-mode= # Listener AckMode. See the spring-kafka documentation.
spring.kafka.listener.ack-time= # Time between offset commits when ackMode is "TIME" or "COUNT_TIME".
spring.kafka.listener.client-id= # Prefix for the listener's consumer client.id property.
spring.kafka.listener.concurrency= # Number of threads to run in the listener containers.
spring.kafka.listener.idle-event-interval= # Time between publishing idle consumer events (no data received).
spring.kafka.listener.log-container-config= # Whether to log the container configuration during initialization (INFO level).
spring.kafka.listener.monitor-interval= # Time between checks for non-responsive consumers. If a duration suffix is not specified, seconds will be used.
spring.kafka.listener.no-poll-threshold= # Multiplier applied to "pollTimeout" to determine if a consumer is non-responsive.
spring.kafka.listener.poll-timeout= # Timeout to use when polling the consumer.
spring.kafka.listener.type=single # Listener type.
spring.kafka.producer.acks= # Number of acknowledgments the producer requires the leader to have received before considering a request complete.
spring.kafka.producer.batch-size= # Default batch size.
spring.kafka.producer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for producers.
spring.kafka.producer.buffer-memory= # Total memory size the producer can use to buffer records waiting to be sent to the server.
spring.kafka.producer.client-id= # ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.producer.compression-type= # Compression type for all data generated by the producer.
spring.kafka.producer.key-serializer= # Serializer class for keys.
spring.kafka.producer.properties.*= # Additional producer-specific properties used to configure the client.
spring.kafka.producer.retries= # When greater than zero, enables retrying of failed sends.
spring.kafka.producer.ssl.key-password= # Password of the private key in the key store file.
spring.kafka.producer.ssl.key-store-location= # Location of the key store file.
spring.kafka.producer.ssl.key-store-password= # Store password for the key store file.
spring.kafka.producer.ssl.key-store-type= # Type of the key store.
spring.kafka.producer.ssl.protocol= # SSL protocol to use.
spring.kafka.producer.ssl.trust-store-location= # Location of the trust store file.
spring.kafka.producer.ssl.trust-store-password= # Store password for the trust store file.
spring.kafka.producer.ssl.trust-store-type= # Type of the trust store.
spring.kafka.producer.transaction-id-prefix= # When non empty, enables transaction support for producer.
spring.kafka.producer.value-serializer= # Serializer class for values.
spring.kafka.properties.*= # Additional properties, common to producers and consumers, used to configure the client.
spring.kafka.ssl.key-password= # Password of the private key in the key store file.
spring.kafka.ssl.key-store-location= # Location of the key store file.
spring.kafka.ssl.key-store-password= # Store password for the key store file.
spring.kafka.ssl.key-store-type= # Type of the key store.
spring.kafka.ssl.protocol= # SSL protocol to use.
spring.kafka.ssl.trust-store-location= # Location of the trust store file.
spring.kafka.ssl.trust-store-password= # Store password for the trust store file.
spring.kafka.ssl.trust-store-type= # Type of the trust store.
spring.kafka.streams.application-id= # Kafka streams application.id property; default spring.application.name.
spring.kafka.streams.auto-startup=true # Whether or not to auto-start the streams factory bean.
spring.kafka.streams.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for streams.
spring.kafka.streams.cache-max-size-buffering= # Maximum memory size to be used for buffering across all threads.
spring.kafka.streams.client-id= # ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.streams.properties.*= # Additional Kafka properties used to configure the streams.
spring.kafka.streams.replication-factor= # The replication factor for change log topics and repartition topics created by the stream processing application.
spring.kafka.streams.ssl.key-password= # Password of the private key in the key store file.
spring.kafka.streams.ssl.key-store-location= # Location of the key store file.
spring.kafka.streams.ssl.key-store-password= # Store password for the key store file.
spring.kafka.streams.ssl.key-store-type= # Type of the key store.
spring.kafka.streams.ssl.protocol= # SSL protocol to use.
spring.kafka.streams.ssl.trust-store-location= # Location of the trust store file.
spring.kafka.streams.ssl.trust-store-password= # Store password for the trust store file.
spring.kafka.streams.ssl.trust-store-type= # Type of the trust store.
spring.kafka.streams.state-dir= # Directory location for the state store.
spring.kafka.template.default-topic= # Default topic to which messages are sent.
```

<font style="color:rgb(76, 73, 72);">源码链接：</font>[<font style="color:rgb(76, 73, 72);">https://github.com/wuyouzhuguli/SpringAll/tree/master/54.Spring-Boot-Kafka</font>](https://github.com/wuyouzhuguli/SpringAll/tree/master/54.Spring-Boot-Kafka)

